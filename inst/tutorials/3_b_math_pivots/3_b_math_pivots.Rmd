---
title: "Class 3: Tidy data and math"
author: "Andrew Ba Tran"
output: 
  learnr::tutorial:
      theme: lumen
      highlight: espresso
      progressive: true
      allow_skip: false
      includes:
        before_body: _navbar.html
runtime: shiny_prerendered
# Do not index/display tutorial by setting `private: true`
private: true
description: >
  Tidy data and math
---


```{css, echo=FALSE}
.pageContent {
padding-top: 64px }
```

```{r setup, include=FALSE}
packages <- c("tidyverse", "lubridate", "rvest", "httr", "remotes")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())), repos = "https://cran.us.r-project.org")  
}

#remotes::install_github("rstudio/gradethis", upgrade="always", quiet=TRUE)
#remotes::install_github("rstudio/learnr", upgrade="always", quiet=TRUE)

library(tidyverse)
library(learnr)
library(gradethis)
library(lubridate)
library(readxl)
library(janitor)
#myurl <- "https://www.cdc.gov/nchs/data/data_acces_files/NCHSURCodes2013.xlsx"
#download.file(myurl, (tf1 <- tempfile(fileext = ".xlsx")), mode = "wb")

#designations <- readxl::read_excel(tf1)
df <- read_csv("https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries.csv")

#county_pop <- read_csv("data/county_population.csv")
county_pop <- read_csv("https://www.andrewbatran.com/data/county_population.csv")

df_new <- df %>% 
  mutate(GEOID=str_c(fipsStateCode, fipsCountyCode))

joined_new <- left_join(df_new, county_pop, by="GEOID")


long_flood <- joined_new %>% 
  #filter(state=="KY") %>% 
  filter(incidentType=="Flood") %>% 
  mutate(year=year(incidentBeginDate)) %>% 
  # extracting months
  mutate(month=month(incidentBeginDate)) %>% 
  # only paying attention to months in current year of data set
  filter(month %in% c(1:8)) %>% 
  filter(year==2020 | year==2021 | year==2022) %>% 
  group_by(year, state) %>% 
  summarize(declarations=n(),
            avg_pop=mean(estimate, na.rm=T),
            median_pop=median(estimate, na.rm=T))

wide_flood <- long_flood %>% 
  pivot_wider(names_from="year",
              values_from="declarations")


fires_wide <- joined_new %>% 
  filter(incidentType=="Fire") %>% 
  mutate(year=year(incidentBeginDate)) %>% 
  count(year, NAME) %>% 
  filter(!is.na(NAME)) %>% 
  pivot_wider(names_from="year", values_from=n)

```

<span style="color:white">welcome to class!</span>

## tidyr

You need to understand the basics of math to tell a story.

Let's say you're looking at this data because some local disaster occurred and you want to answer the question:

* Are things worse now than they were before? 
* Which place has it worst and most recently? 
  * Because you can go visit that place and find victims to anchor the story narratively
  
Being able to come up with types of questions and answer them yourself using raw data will help you stand apart from the competition. 

Because you're working with raw data intended for use by an agency for one thing, you'll need to be able to reshape the data so you can do your own analysis, which will include math (such as difference, percents, percent change, and per capita).

One advanced technique for transforming data you'll learn in this section is from the **tidyr** package.

* `pivot_wider()`
* `pivot_longer()`

Now, these used to be called `gather()` and `spread()` but the language is a bit clearer now.

Pivots in R mean something else entirely than pivots in Excel.

In Excel, pivot tables are used to group and summarize data.

In R, you pivot data as in you reshape it. This way you can do math easier across all rows.

Here's how it works (pay attention to the colors):

```{r pivot-image1, out.width = "400px", echo=F, eval=F}
knitr::include_graphics("images/original-dfs-tidy.png")
```


```{r pivot-image2, out.width = "400px", echo=F}
knitr::include_graphics("images/tidyr-pivoting.gif")
```

Let's start with this data that we last ended up with. 

But this time comment comment out the second line so we include all states with floods this time.

And in the 10th line, add "state" as a second argument in the `group_by()` option after "year".

```{r what, exercise=TRUE}
long_flood <- joined_new %>% 
  filter(incidentType=="Flood") %>% 
  mutate(year=year(incidentBeginDate)) %>% 
  # extracting months
  mutate(month=month(incidentBeginDate)) %>% 
  # only paying attention to months in current year of data set
  filter(month %in% c(1:8)) %>% 
  filter(year==2020 | year==2021 | year==2022) %>% 
  group_by(year) %>% 
  summarize(declarations=n(),
            avg_pop=mean(estimate, na.rm=T),
            median_pop=median(estimate, na.rm=T))

long_flood
```

```{r what-solution}
long_flood <- joined_new %>% 
  filter(incidentType=="Flood") %>% 
  mutate(year=year(incidentBeginDate)) %>% 
  # extracting months
  mutate(month=month(incidentBeginDate)) %>% 
  # only paying attention to months in current year of data set
  filter(month %in% c(1:8)) %>% 
  filter(year==2020 | year==2021 | year==2022) %>% 
  group_by(year, state) %>% 
  summarize(declarations=n(),
            avg_pop=mean(estimate, na.rm=T),
            median_pop=median(estimate, na.rm=T))

long_flood
```

```{r what-hint}
Use a # to comment out.
Also, you don't need quotations around column names in
group_by() unless there's a space in the column names.
Multiple arguments in group_by() are separated by a comma.
```

```{r what-check}
grade_this_code()
```

Okay, we have tidy data! Each variable is in its own column. Each case is in its own row and each value is in its own cell.

This makes it easier to mutate and manipulate (and is also the preferable data structure for most data viz tools).

However, if we wanted to compare 2020 declaration counts to 2021 and 2022 in each state, that would be difficult.

## pivot_wider()

So we need to turn this long data into wide data using `pivot_wider()`

You need to identify what column you want to pull the new column names from and which column the values are stored in ("year" and "declarations" respectively. In this specific circumstance ("pivot_") you'll need to put the column names in quotation marks.

We'll also need to drop the `avg_pop` and `median_pop` columns or else the pivot will fail.

To drop columns, you use the `-` subtract sign in the `select()` function.

```{r pivot_wider, exercise=TRUE}
wide_flood <- long_flood %>% 
  select(-avg_pop, -median_pop) %>% 
  pivot_wider(names_from="____",
              values_from="____________")

wide_flood
```

```{r pivot_wider-solution}
wide_flood <- long_flood %>% 
  select(-avg_pop, -median_pop) %>% 
  pivot_wider(names_from="year",
              values_from="declarations")

wide_flood
```

```{r pivot_wider-hint}
In this instance, you do need to put the column names in quotation marks.
```

```{r pivot_wider-check}
grade_this_code()
```

Great job! We can clearly see most states had flooding in only one year. 

Kentucky had 50 in 2021 and 20 in 2022 (Okay, the number may change in 2022 depending on when you pull this data and how unlucky Kentucky continues to be). 

We knew that from our last section but now we can see that it's the only state that had floods in both years.

But we can now answer one of our questions:

* Which place has it worst and most recently? 

If you paginate through the results you'll see one state in particular went from no floods in 2021 to 19 in 2022.

Next, we can use `summarize()` and `mutate()` to do some math to answer our first question:

* Are things worse now than they were before? 

Note: Because the column names we care about starts with a number, we need to surround the column names ``like `this` in the code.`` The key to the left of the `1` on the keyboard. This is also what you'd have to do if the column names had spaces in them.

Add up all the floods by year with summarize and then add a column that calculates the percent change between 2022 and 2021.

Don't forget to add the argument that ignores any `NA` values in the `sum()` formula.

```{r wide_flood_summary, exercise=TRUE}
flood_percent_change <- wide_flood %>% 
  summarize(`2020`=sum(______, _____=T),
            `2021`=sum(______, _____=T),
            `2022`=sum(______, _____=T)) %>% 
  ______(percent_change=(round((`____`-`____`)/`____`*100,1)))

flood_percent_change
```

```{r wide_flood_summary-solution}
flood_percent_change <- wide_flood %>% 
  summarize(`2020`=sum(`2020`, na.rm=T),
            `2021`=sum(`2021`, na.rm=T),
            `2022`=sum(`2022`, na.rm=T)) %>% 
  mutate(percent_change=(round((`2022`-`2021`)/`2021`*100,1)))

flood_percent_change
```

```{r wide_flood_summary-hint}
The formula for percent change is (new-old)/old*100. Also remember the differences between aggregating a data frame and adding a column to an existing data frame.
```

```{r wide_flood_summary-check}
grade_this_code()
```


## pivot_wider() multiple

What's really powerful about `pivot_wider()` is the option to be able to draw values from more than one column.

Adjust the code below:

1. Delete the `-avg_pop` argument in line 2 (and the comma)
2. in `values_from`, instead of "declarations" type in `c("declarations", "avg_pop")

See what happens. *Also, type it in, don't copy and paste otherwise you'll run into syntax issues.*

```{r pivot_wider_more, exercise=TRUE}
wide_flood_more <- long_flood %>% 
  select(-avg_pop, -median_pop) %>% 
  pivot_wider(names_from="year",
              values_from="declarations")

wide_flood_more
```


```{r pivot_wider_more-solution}
wide_flood_more <- long_flood %>% 
  select(-median_pop) %>% 
  pivot_wider(names_from="year",
              values_from=c("declarations", "avg_pop"))

wide_flood_more
```

```{r pivot_wider_more-hint}
Be careful about syntax.
Also, you still want to pull names from "year"
```

```{r pivot_wider_more-check}
grade_this_code()
```

You'll have to paginate a bit but you can see that the declarations and average are now prefixes to the `_2021` etc years.

You could also bring in the median values this way if you want.

Okay, now that we know how to make long data to wide, let's convert wide data to long.

## pivot_longer()

Sometimes you'll get data that looks like this:

```{r fire_data}
fires_wide
```

These are the declared fire disasters in each county since 1956.

A state or column in one row and every column after is a different year of data.

This is not tidy data. Every year should be its own row. This is fine if we want to calculate changes between individual years.

But if we wanted to visualize this, we'd need to transform it long.

We want to increase the number of rows and decrease the number of columns.

We'll use the `pivot_longer()` function which needs:

1. What columns to focus on `cols=`
2. What to name the column with the names of the columns `names_to=`
3. What to name the column with the values `values_to=`


```{r pivot_longer, exercise=TRUE}
# We could do cols=`1967`:`2022`
# or we could do the number of columns in the dataframe as in cols=2:41
# let's do the first option in this one

fires_wide %>% 
  pivot_______(cols=_____________,
               _____to="year",
               _______to="declarations")
  
```


```{r pivot_longer-solution}
fires_wide %>% 
  pivot_longer(cols=`1967`:`2022`,
               names_to="year",
               values_to="declarations")
```

```{r pivot_longer-hint}
Make sure you name the arguments correctly.
```

```{r pivot_longer-check}
grade_this_code()
```


Alright! We did it!

You now have a handle on all the biggest verbs used to wrangle and transform data.

There are many more functions that do more specific things, of course.

But this will hopefully get you started on your way. Everything else you may have questions on how to do has probably been asked and answered out in the R online community.

## Class II - Done

Stop this tutorial in the `Render` tab of RStudio (press the stop button).

Alright, almost there.

Breath in and out. Great job!

Next, we're going to go over how to visualize your data using the library `ggplot2`.

